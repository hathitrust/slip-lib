# -------------------------------------------------------------------
# Run-31 config: LSS SLIP chunking model. 
#
# DEVELOPMENT configuration emulating run 10, 11.
#
# -------------------------------------------------------------------

report_to_email_address      = tburtonw@umich.edu
report_from_email_address    = "SLIP Mailer" <dlps-help@umich.edu>

#
# --------------------- Class Configuration ---------------------------
#

# ---------------------------------------------------------------------
#                            Extractor
#  ---------------------------------------------------------------------
#  Extracts files to disk based on document_data_uses_class
#  configuration (below)
document_data_extractor_class = Document::Extractor

# ---------------------------------------------------------------------
#  Extension
#  ---------------------------------------------------------------------
#  Extra child fields and ID field as a function of
#  document_data_tokenizer_granulatity and document_data_class_type
#  configuration (below).
document_extension_base_class = Document::Doc::Extension

# ---------------------------------------------------------------------
#                            Tokenizer
# ---------------------------------------------------------------------
# Document::Tokenizer::{File|Token}
#
# Tokenizer subclasses implement text chunking for a Solr document "ocr" field
#   Tokenizer::File [OCR file content or XML files' text() nodes]
#      granularity=N
#         o "ocr" field = 1..N file's content from zip for full-text experimental indexing.
#                         N=1 is special case for normal item-level page indexing.
#      granularity=0
#         o "ocr" field = ALL files concatenated for normal large-scale indexing
#   Tokenizer::Token
#      granularity = 1..N
#         o "ocr" field = one of X "balanced" chunks of N tokens
#           where X minimizes the difference between tokens per chunk and N
#      granularity=0
#         o "ocr" field = ALL content from files, concatenated
document_data_tokenizer_class = Document::Tokenizer::File
document_data_tokenizer_granulatity = 0

# ---------------------------------------------------------------------
#            Document::Doc HAS-A: ::Data, ::vSolrMetadataAPI
# ---------------------------------------------------------------------
# METS data USEs configuration controls which files are extracted from
# the zip.
#
document_data_uses_class = Document::Conf::uses_1

# Document::Doc::Data::{File,Token}, types: flat,nested. Typically
# Data::<subclass> should match Tokenizer::<subclass>
#
document_data_class = Document::Doc::Data::File
document_data_class_type = flat

# Algorithm packages found under Document::Algorithms that implement
# the and only the execute() method. Typically used to apply specific
# additional processint to text data. Applied in order listed.
#
document_data_algorithm_classes = DeHyphenate

# Document::Doc::vSolrMetadataAPI::<various>
#
document_metadata_class  = Document::Doc::vSolrMetadataAPI::Schema_LS_11

# ---------------------------------------------------------------------
# Plugins
# ---------------------------------------------------------------------
# Typically used to create additional Solr document fields from member
# data available on the ::Data and ::vSolrMetadataAPI objects.
#
plugin_for_Document::Doc::Data::File = Plugin_ratios

#
# Sizes
#
num_shards_list    = 3
queue_slice_size   = 5

#
# Server key to virtual server URI
#
engine_for_shard_3  = http://solr-sdr-dev:8111/dev-3

#
# shard to index directory map
#
dir_for_shard_3    = /htsolr/lss-dev/solrs/3.6/3/data/index

#
# **** Driver ****
#
# Default          = 0 in common.conf
driver_driven      = 0

#
# host-to-shard(s) map
#
shards_of_host_solr-sdr-dev = 3

#
# shard(s)-to-host map
#
host_of_shard_3    = solr-sdr-dev

#
# producer hosts / shards
#
producers_per_shard = 2
# producers_per_host should be floor of (num_shards * producers_per_shard) / num_hosts
producers_per_host = 3
producer_hosts     = grog
solr_hosts         = alamo

#
# Tomcat pattern
#
tomcat_pattern = /l/local/apache-tomcat-slip-dev\s+-D

#
# Error triage - large-scale
#
# Solr could not parse doc
max_indx_errors = 1000;
# Could not create OCR for Solr doc
max_ocr__errors = 1000;
# Could not get metadata for Solr doc
max_meta_errors = 5000;
# Server unavailable
max_serv_errors = 1000;
# N >= numhosts * numproducers/host * queue_slice_size
# Currently 5 * 5 * 5 = 125
max_no_indexer_avail = 130;
# Serious stuff
max_crit_errors = 5;
