# -------------------------------------------------------------------
# Run-11 config: Production VuFind metadata based schema -- nextSLIP
#  Updated for Solr 4 syntax and  Schema_LS_12 enum schema change
# -------------------------------------------------------------------

# Mounts Solr server flag dir on the build machines.  Supports
# swapping between Daily and re-idexing run and signals when Core
# Services can release Daily index. DO NOT EDIT.
shared_flags_dir = /htsolr/lss/flags

#
# Optimization to one segment controls
#
full_optimize_supported = 1
# limit shard 2nd segment to ~500GB/12
full_optimize_trigger_size = 40
full_optimize_all_shards_trigger_size = 80
# may be dynamically over-ridden when full_optimize_all_shards_trigger_size is reached
max_full_optimizing_shards = 1

#
# Lucene checkIndex program control. check-j run Lucene checkIndex if
# check_index_supported=1. check-j always counts number of segments.
#
check_index_supported = 1
check_index_day_of_week = Tuesday
check_index_java_cmd = java -Xmx10g -Xms10g -cp /l/local/bin/lucene-core.jar -ea:org.apache.lucene... org.apache.lucene.index.CheckIndex  /htsolr/lss/shards/__SHARD__/data/index ;



# ========================== Class Configurations ======================


# ----------------------------------------------------------------------
#                            Extractor
#  ---------------------------------------------------------------------
#  Extracts files to disk based on document_data_uses_class
#  configuration (below)
document_data_extractor_class = Document::Extractor

# ----------------------------------------------------------------------
#  Extension
#  ---------------------------------------------------------------------
#  Extra child fields and ID field as a function of
#  document_data_tokenizer_granulatity and document_data_class_type
#  configuration (below).
document_extension_base_class = Document::Doc::Extension

# ---------------------------------------------------------------------
#                            Tokenizer
# ---------------------------------------------------------------------
# Document::Tokenizer::{File|Token}
#
# Tokenizer subclasses implement text chunking for a Solr document "ocr" field
#   Tokenizer::File [OCR file content or XML files' text() nodes]
#      granularity =N
#         o "ocr" field = 1..N file's content from zip for full-text experimental indexing.
#                         N =1 is special case for normal item-level page indexing.
#      granularity =0
#         o "ocr" field = ALL files concatenated for normal large-scale indexing
#   Tokenizer::Token
#      granularity = 1..N
#         o "ocr" field = one of X "balanced" chunks of N tokens
#           where X minimizes the difference between tokens per chunk and N
#      granularity =0
#         o "ocr" field = ALL content from files, concatenated
document_data_tokenizer_class = Document::Tokenizer::File
document_data_tokenizer_granulatity = 0

# ---------------------------------------------------------------------
#            Document::Doc HAS-A: ::Data, ::vSolrMetadataAPI
# ---------------------------------------------------------------------
# METS data USEs configuration controls which files are extracted from
# the zip.
#
document_data_uses_class = Document::Conf::uses_1

# Document::Doc::Data::{File,Token}, types: flat,nested. Typically
# Data::<subclass> should match Tokenizer::<subclass>
#
document_data_class = Document::Doc::Data::File
document_data_class_type = flat

# Algorithm packages found under Document::Algorithms that implement
# the and only the execute() method. Typically used to apply specific
# additional processint to text data. Applied in order listed.
#
document_data_algorithm_classes = DeHyphenate

# Document::Doc::vSolrMetadataAPI::<various>
#
document_metadata_class = Document::Doc::vSolrMetadataAPI::Schema_LS_12

# ---------------------------------------------------------------------
# Plugins
# ---------------------------------------------------------------------
# Typically used to create additional Solr document fields from member
# data available on the ::Data and ::vSolrMetadataAPI objects.
# Example:
# plugin_for_Document::Doc::Data::File = Plugin_ratios

#
# Sizes
#
num_shards_list = 1|2|3|4|5|6|7|8|9|10|11|12
queue_slice_size = 20

#
# Server key to virtual server URI
#
engine_for_shard_1  = http://solr-sdr-build-1:8091/build-1/core-1
engine_for_shard_2  = http://solr-sdr-build-2:8092/build-2/core-1
engine_for_shard_3  = http://solr-sdr-build-3:8093/build-3/core-1
engine_for_shard_4  = http://solr-sdr-build-4:8094/build-4/core-1
engine_for_shard_5  = http://solr-sdr-build-5:8095/build-5/core-1
engine_for_shard_6  = http://solr-sdr-build-6:8096/build-6/core-1
engine_for_shard_7  = http://solr-sdr-build-7:8097/build-7/core-1
engine_for_shard_8  = http://solr-sdr-build-8:8098/build-8/core-1
engine_for_shard_9  = http://solr-sdr-build-9:8099/build-9/core-1
engine_for_shard_10 = http://solr-sdr-build-10:8100/build-10/core-1
engine_for_shard_11 = http://solr-sdr-build-11:8101/build-11/core-1
engine_for_shard_12 = http://solr-sdr-build-12:8102/build-12/core-1


#
# shard to index directory map
#
dir_for_shard_1     = /htsolr/lss/shards/1/core-1/data/index
dir_for_shard_2     = /htsolr/lss/shards/2/core-1/data/index
dir_for_shard_3     = /htsolr/lss/shards/3/core-1/data/index
dir_for_shard_4     = /htsolr/lss/shards/4/core-1/data/index
dir_for_shard_5     = /htsolr/lss/shards/5/core-1/data/index
dir_for_shard_6     = /htsolr/lss/shards/6/core-1/data/index
dir_for_shard_7     = /htsolr/lss/shards/7/core-1/data/index
dir_for_shard_8     = /htsolr/lss/shards/8/core-1/data/index
dir_for_shard_9     = /htsolr/lss/shards/9/core-1/data/index
dir_for_shard_10    = /htsolr/lss/shards/10/core-1/data/index
dir_for_shard_11    = /htsolr/lss/shards/11/core-1/data/index
dir_for_shard_12    = /htsolr/lss/shards/12/core-1/data/index

#
# **** Driver ****
#
# Default = 0 in common.conf
driver_driven = 1

#
# host-to-shard(s) map
#
shards_of_host_solr-sdr-build-1/core-1  = 1
shards_of_host_solr-sdr-build-2/core-1  = 2
shards_of_host_solr-sdr-build-3/core-1  = 3
shards_of_host_solr-sdr-build-4/core-1  = 4
shards_of_host_solr-sdr-build-5/core-1  = 5
shards_of_host_solr-sdr-build-6/core-1  = 6
shards_of_host_solr-sdr-build-7/core-1  = 7
shards_of_host_solr-sdr-build-8/core-1  = 8
shards_of_host_solr-sdr-build-9/core-1  = 9
shards_of_host_solr-sdr-build-10/core-1 = 10
shards_of_host_solr-sdr-build-11/core-1 = 11
shards_of_host_solr-sdr-build-12/core-1 = 12

#
# shard(s)-to-host map
#
host_of_shard_1  = solr-sdr-build-1/core-1
host_of_shard_2  = solr-sdr-build-2/core-1
host_of_shard_3  = solr-sdr-build-3/core-1
host_of_shard_4  = solr-sdr-build-4/core-1
host_of_shard_5  = solr-sdr-build-5/core-1
host_of_shard_6  = solr-sdr-build-6/core-1
host_of_shard_7  = solr-sdr-build-7/core-1
host_of_shard_8  = solr-sdr-build-8/core-1
host_of_shard_9  = solr-sdr-build-9/core-1
host_of_shard_10 = solr-sdr-build-10/core-1
host_of_shard_11 = solr-sdr-build-11/core-1
host_of_shard_12 = solr-sdr-build-12/core-1

#
# producer hosts / shards
#

# producers_per_host should be ceiling of:
# (num_shards * producers_per_shard) / num_hosts that are active
# So:
# (12 shards * 3 producers_per_shard) / 4 (earlgrey-*) = 36/4 = 9
#
# Optimal per host/shard combos for 4 hosts and 12 shards follow. Note
# earlgrey-* have 24 CPUs.
#
#  host:  9 12 15 18 21 |24| 27 30 33
# shard:  3  4  5  6  7 | 8|  9 10 11
producers_per_host = 24
producers_per_shard = 8
producer_hosts = earlgrey-1|earlgrey-2|earlgrey-3|earlgrey-4
solr_hosts = solr-sdr-build-1/core-1|solr-sdr-build-2/core-1|solr-sdr-build-3/core-1|solr-sdr-build-4/core-1|solr-sdr-build-5/core-1|solr-sdr-build-6/core-1|solr-sdr-build-7/core-1|solr-sdr-build-8/core-1|solr-sdr-build-9/core-1|solr-sdr-build-10/core-1|solr-sdr-build-11/core-1|solr-sdr-build-12/core-1

#
# Tomcat pattern
#
tomcat_pattern = /l/local/apache-tomcat-lss-__SHARD__\s+-D


#
# Error triage - large-scale
#
# Solr could not parse doc
max_indx_errors = 1000;
# Could not create OCR for Solr doc
max_ocr__errors = 1000;
# Could not get metadata for Solr doc
max_meta_errors = 5000;
# Server unavailable
max_serv_errors = 10000;
# N > = numhosts * numproducers/host * queue_slice_size
# Currently 5 * 5 * 5 = 125
max_no_indexer_avail = 130;
# Serious stuff
max_crit_errors = 5;
